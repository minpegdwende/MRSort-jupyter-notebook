{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the parameters of a MRSort model using the metaheuristic algorithm (oso-pymcda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metaheuristic code at our disposal comes from github (https://github.com/oso/pymcda) developped by Olivier Sobrie). In addition to this code, we took into account mainly these adaptations : the learning a MRSort model from \"a duplicated data set\", the generation of statistic plots on the learning results. The code originally in Python 2 has been upgraded to some extent to Python 3. This code is located in the \"oso-pymcda/\" directory, which is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before digging into the code, here are some requirements to have : \n",
    "   * The library matplotlib.pyplot need to be installed. This can be done with the command line below (preferably using pip  - that can be also installed following the instructions of this link : https://pip.pypa.io/en/stable/installing/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.16.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Download and install CPLEX Optimization Studio : https://www.ibm.com/products/ilog-cplex-optimization-studio (choose the student/teacher free edition) and follow the steps. Help could be found here : https://www.ibm.com/support/knowledgecenter/SSSA5P_12.9.0/ilog.odms.studio.help/Optimization_Studio/topics/COS_home.html\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set the global variable *DATADIR* so that it contains the right path from the root to this working directory  **MRSort-jupyter-notebook** . Here an example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATADIR=/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook\n"
     ]
    }
   ],
   "source": [
    "%env DATADIR /Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpful articles on MCDA/MRSort model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to grasp the methodology of MCDA and have a overview of the metaheuristic that is used in this notebook, we give here below some useful related articles :\n",
    "   * [A new decision support model for preanesthetic evaluation](papers/Sobrie_and_al.pdf)\n",
    "   * [Learning monotone preferences using a majority rule sorting model](papers/Sobrie_Mousseau_Pirlot.pdf) (in particular, this explains with details the procedure of the metaheuristic)\n",
    "   * [Learning the Parameters of a Multiple Criteria Sorting Method Based on a Majority Rule](papers/Leroy_Mousseau_Pirlot.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code gathers mainly 2 parts : \n",
    "   * the first component on the generation, learning and tests of a parametered MRSort model (one running of the learning algorithm followed by tests),\n",
    "   * the second component on the compilation of series of parametered MRSort runnings and the output of interesting statistic plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to move to our working environment and run the main file in order to keep in memory the implementations of functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run oso-pymcda/apps/random_model_generation_msjp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, to achieve our goal we follow these steps : \n",
    "   * <u>Step 1</u> : initialize the required parameters,\n",
    "   * <u>Step 2</u> : generate a new random MRSort model (profile, weights, threshold),\n",
    "   * <u>Step 3</u> : generate randomly a set of alternatives and performance table,\n",
    "   * <u>Step 4</u> : assign categories to these alternatives to yield a learning set,\n",
    "   * <u>Step 5</u> : run the MRSort metaheuristic learning algorithm,\n",
    "   * <u>Step 6</u> : validate the learning of the random model (% of classification \"initial model VS learned model\" on the learning set)\n",
    "   * <u>Step 7</u> : test the learned algorithm on a benchmarch of alternatives examples\n",
    "   * <u>Step 8</u> : show the important results (summarized also in a csv file)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : initialize the required parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we initialize the parameters of one running for the learning algorithm. Respectively, we have : \n",
    "   * *nb_categories* : the number of categories (classes)\n",
    "   * *nb_criteria* : the number of criteria taken in consideration of the MCDA problem\n",
    "   * *nb_alternatives* : the number of alternatives (for the learning set)\n",
    "   * *dir_criteria* : the list of order/direction on preferences of the criteria  (1 for a criteria to maximize)\n",
    "   * *l_dupl_criteria* : the list of criteria (indices) to duplicate during the learning process\n",
    "   * *nb_tests* : the number of tests (number of alternatives) to carry out in order to compare the performance of the learned model regarding the initial model\n",
    "   * *nb_models* : the number of models that independantly learn during one running of the learning algorithm\n",
    "   * *meta_l* : the number of iteration of the metaheuristic algorithm (outer loop)\n",
    "   * *meta_ll* : the number of iteration of the metaheuristic algorithm (inner loop)\n",
    "   * *meta_nb_models* : the number of models (population) handled by the metaheuristic (evolutionary) algorithm during the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_categories = 2 # fixed\n",
    "nb_criteria = 5\n",
    "nb_alternatives = 100\n",
    "dir_criteria = [1]*nb_criteria # fixed to 1 for all criteria\n",
    "l_dupl_criteria = list(range(nb_criteria))[:1]\n",
    "\n",
    "# parameters of test\n",
    "nb_tests = 10000\n",
    "nb_models = 10\n",
    "\n",
    "# parameters of the metaheuristic MRSort\n",
    "meta_l = 10\n",
    "meta_ll = 10\n",
    "meta_nb_models = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create an instance of the one running of the learning algorithm as follows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = RandMRSortLearning(nb_alternatives, nb_categories, \n",
    "        nb_criteria, dir_criteria, l_dupl_criteria, \n",
    "        nb_tests, nb_models, meta_l, meta_ll, meta_nb_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 to 4 : generate a new random MRSort model, alternatives and assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here 3 steps are performs one after the other in the same function. We generate a new random MRSort, then we generate alternatives, and finally we assign these alternatives in 2 categories regarding the MRSort rule of the given model. In addition to these 3 operations, we introduce a coefficient that enable us to control the balance between the set of alternatives (number of alternatives) sorted in the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.generate_random_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look on the model that have been generated :\n",
    "   * generated parameters of the model MRSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c1    c2    c3    c4    c5 \n",
      "b1 0.927 0.433 0.082 0.071 0.137 \n"
     ]
    }
   ],
   "source": [
    "inst.model.bpt.display() # display the limit profile of the random model b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c1    c2    c3    c4    c5 \n",
      "w 0.157 0.338 0.052 0.144 0.308 \n"
     ]
    }
   ],
   "source": [
    "inst.model.cv.display() # display the weights of each criteria of the model w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda\t0.633\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda\\t%.7s\" % inst.model.lbda) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * performance table of generated alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        c1    c2    c3    c4    c5 \n",
      "a1   0.616 0.913 0.789 0.983  0.64 \n",
      "a10  0.282 0.506 0.517 0.915 0.012 \n",
      "a100  0.12 0.636 0.774 0.312 0.234 \n",
      "a11  0.312 0.644 0.319  0.99 0.489 \n",
      "a12  0.558 0.062 0.026  0.24 0.518 \n",
      "a13  0.804 0.224 0.834 0.352 0.739 \n",
      "a14  0.404 0.624 0.465 0.448 0.753 \n",
      "a15  0.897 0.471  0.38 0.983 0.722 \n",
      "a16   0.39 0.131  0.98 0.442 0.984 \n",
      "a17  0.544 0.788  0.38  0.37  0.67 \n",
      "a18  0.785 0.339 0.068 0.396 0.332 \n",
      "a19  0.805 0.017   0.3 0.387 0.789 \n",
      "a2   0.504 0.191 0.616 0.624  0.03 \n",
      "a20  0.457 0.944 0.286 0.664 0.362 \n",
      "a21  0.209 0.846 0.349 0.624 0.385 \n",
      "a22  0.079 0.712 0.382 0.915 0.731 \n",
      "a23  0.094 0.662 0.237 0.301 0.793 \n",
      "a24  0.691 0.469 0.209 0.789 0.642 \n",
      "a25   0.91 0.389 0.802 0.722  0.34 \n",
      "a26  0.213 0.348 0.351 0.498 0.567 \n",
      "a27  0.186 0.856  0.93 0.301 0.151 \n",
      "a28  0.005  0.62 0.249 0.032 0.437 \n",
      "a29  0.664  0.87 0.245 0.412 0.053 \n",
      "a3    0.04 0.585 0.525 0.312 0.859 \n",
      "a30  0.496 0.687 0.743 0.902 0.266 \n",
      "a31  0.845 0.326 0.552 0.801 0.987 \n",
      "a32  0.983 0.193 0.694 0.932 0.297 \n",
      "a33  0.378 0.864 0.348 0.723 0.494 \n",
      "a34  0.785 0.673 0.282 0.248 0.792 \n",
      "a35  0.828 0.423 0.171 0.544 0.377 \n",
      "a36  0.673 0.923 0.074 0.141 0.385 \n",
      "a37  0.012 0.585 0.195 0.444 0.458 \n",
      "a38  0.322 0.019  0.25 0.842 0.152 \n",
      "a39  0.622 0.179  0.73 0.582 0.521 \n",
      "a4    0.34 0.132  0.31 0.232 0.363 \n",
      "a40  0.188 0.481 0.439 0.056 0.053 \n",
      "a41  0.554 0.615 0.198 0.839 0.791 \n",
      "a42  0.814 0.215 0.702 0.009 0.631 \n",
      "a43   0.51 0.499 0.065 0.861 0.732 \n",
      "a44  0.066 0.668 0.857  0.99 0.804 \n",
      "a45  0.913 0.043 0.657 0.629 0.843 \n",
      "a46  0.764 0.074 0.539 0.573 0.916 \n",
      "a47  0.653 0.673 0.085 0.306 0.605 \n",
      "a48  0.683 0.948 0.815  0.86 0.533 \n",
      "a49  0.235 0.643 0.598 0.343 0.021 \n",
      "a5   0.706 0.065 0.302 0.373 0.364 \n",
      "a50  0.131 0.808 0.196 0.586 0.322 \n",
      "a51  0.692 0.136 0.709 0.007 0.213 \n",
      "a52  0.662 0.222 0.343 0.754 0.886 \n",
      "a53  0.494 0.407 0.822 0.964 0.207 \n",
      "a54  0.732 0.251 0.602 0.427 0.248 \n",
      "a55  0.479  0.24 0.411 0.085 0.024 \n",
      "a56  0.004 0.139 0.764 0.159 0.085 \n",
      "a57  0.426 0.318 0.392  0.96  0.07 \n",
      "a58  0.128 0.445 0.872  0.69 0.804 \n",
      "a59  0.632 0.908 0.353 0.241 0.894 \n",
      "a6   0.825 0.846 0.729 0.589 0.456 \n",
      "a60  0.955 0.024  0.36 0.437 0.737 \n",
      "a61  0.598 0.668 0.364  0.33 0.641 \n",
      "a62  0.355 0.929 0.836  0.35 0.714 \n",
      "a63  0.691 0.833 0.982 0.611 0.264 \n",
      "a64  0.893 0.414 0.977 0.853 0.477 \n",
      "a65  0.576 0.742 0.271 0.195 0.958 \n",
      "a66  0.982 0.829 0.778 0.356 0.963 \n",
      "a67  0.367 0.715 0.296 0.547 0.328 \n",
      "a68  0.227 0.648 0.223 0.593 0.088 \n",
      "a69  0.494 0.474 0.805 0.824 0.944 \n",
      "a7   0.298 0.241 0.565 0.855 0.472 \n",
      "a70  0.655 0.356 0.355 0.748 0.097 \n",
      "a71  0.016 0.155 0.709 0.086 0.875 \n",
      "a72  0.555 0.765 0.279 0.055 0.403 \n",
      "a73  0.029 0.738 0.515 0.169 0.054 \n",
      "a74  0.597 0.792 0.939 0.629 0.439 \n",
      "a75   0.79 0.428 0.701 0.586 0.815 \n",
      "a76  0.529 0.366 0.836 0.982 0.479 \n",
      "a77  0.317 0.928 0.473 0.639 0.493 \n",
      "a78  0.321 0.959 0.525 0.418 0.967 \n",
      "a79  0.805 0.278 0.944 0.476 0.396 \n",
      "a8   0.619 0.154 0.032 0.579 0.223 \n",
      "a80  0.336 0.216 0.818 0.055 0.928 \n",
      "a81  0.345  0.38 0.422 0.431 0.788 \n",
      "a82  0.453 0.845 0.902 0.999 0.027 \n",
      "a83  0.564  0.22 0.805 0.431  0.83 \n",
      "a84   0.53 0.622 0.831 0.812 0.089 \n",
      "a85  0.758 0.112 0.318 0.854 0.165 \n",
      "a86  0.861 0.454 0.961 0.951 0.481 \n",
      "a87  0.806 0.292 0.298 0.027 0.645 \n",
      "a88  0.534 0.133 0.074 0.801 0.784 \n",
      "a89  0.769 0.786  0.49 0.527 0.869 \n",
      "a9   0.127 0.375 0.279 0.813 0.188 \n",
      "a90  0.374  0.51 0.591  0.03 0.217 \n",
      "a91   0.18 0.909 0.336 0.785 0.833 \n",
      "a92   0.83 0.793 0.618 0.796 0.646 \n",
      "a93  0.619 0.462  0.64 0.556 0.951 \n",
      "a94  0.772 0.834 0.727 0.572 0.364 \n",
      "a95  0.288 0.065 0.627 0.237 0.336 \n",
      "a96  0.164 0.781 0.567 0.045 0.242 \n",
      "a97  0.576 0.479 0.208 0.524 0.685 \n",
      "a98   0.79 0.726 0.505 0.667 0.084 \n",
      "a99  0.753 0.458 0.851 0.716 0.256 \n"
     ]
    }
   ],
   "source": [
    "inst.pt.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * the result of the assignment of alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     category\n",
      "a1       cat1\n",
      "a10      cat2\n",
      "a100     cat1\n",
      "a11      cat1\n",
      "a12      cat2\n",
      "a13      cat2\n",
      "a14      cat1\n",
      "a15      cat1\n",
      "a16      cat2\n",
      "a17      cat1\n",
      "a18      cat2\n",
      "a19      cat2\n",
      "a2       cat2\n",
      "a20      cat1\n",
      "a21      cat1\n",
      "a22      cat1\n",
      "a23      cat1\n",
      "a24      cat1\n",
      "a25      cat2\n",
      "a26      cat2\n",
      "a27      cat1\n",
      "a28      cat1\n",
      "a29      cat2\n",
      "a3       cat1\n",
      "a30      cat1\n",
      "a31      cat2\n",
      "a32      cat1\n",
      "a33      cat1\n",
      "a34      cat1\n",
      "a35      cat2\n",
      "a36      cat1\n",
      "a37      cat1\n",
      "a38      cat2\n",
      "a39      cat2\n",
      "a4       cat2\n",
      "a40      cat2\n",
      "a41      cat1\n",
      "a42      cat2\n",
      "a43      cat1\n",
      "a44      cat1\n",
      "a45      cat2\n",
      "a46      cat2\n",
      "a47      cat1\n",
      "a48      cat1\n",
      "a49      cat2\n",
      "a5       cat2\n",
      "a50      cat1\n",
      "a51      cat2\n",
      "a52      cat2\n",
      "a53      cat2\n",
      "a54      cat2\n",
      "a55      cat2\n",
      "a56      cat2\n",
      "a57      cat2\n",
      "a58      cat1\n",
      "a59      cat1\n",
      "a6       cat1\n",
      "a60      cat1\n",
      "a61      cat1\n",
      "a62      cat1\n",
      "a63      cat1\n",
      "a64      cat2\n",
      "a65      cat1\n",
      "a66      cat1\n",
      "a67      cat1\n",
      "a68      cat2\n",
      "a69      cat1\n",
      "a7       cat2\n",
      "a70      cat2\n",
      "a71      cat2\n",
      "a72      cat1\n",
      "a73      cat2\n",
      "a74      cat1\n",
      "a75      cat2\n",
      "a76      cat2\n",
      "a77      cat1\n",
      "a78      cat1\n",
      "a79      cat2\n",
      "a8       cat2\n",
      "a80      cat2\n",
      "a81      cat2\n",
      "a82      cat2\n",
      "a83      cat2\n",
      "a84      cat2\n",
      "a85      cat2\n",
      "a86      cat1\n",
      "a87      cat2\n",
      "a88      cat2\n",
      "a89      cat1\n",
      "a9       cat2\n",
      "a90      cat1\n",
      "a91      cat1\n",
      "a92      cat1\n",
      "a93      cat1\n",
      "a94      cat1\n",
      "a95      cat2\n",
      "a96      cat1\n",
      "a97      cat1\n",
      "a98      cat2\n",
      "a99      cat1\n"
     ]
    }
   ],
   "source": [
    "inst.aa.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: run the MRSort metaheuristic learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following step represents one model iteration of the metaheuristic algorithm. This iteration learns with a single model the initial model from the previous learning set (performance table and assignments of alternatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) : 0.550408\n"
     ]
    }
   ],
   "source": [
    "inst.num_model = 0 # initialization of the position of the model that is currently learning\n",
    "execution_time = inst.run_mrsort()\n",
    "print(\"Time (s) : %f\" % execution_time) # computational time of the running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the parameters of the model learned :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        c1     c1d      c2      c3    c4    c5 \n",
      "b1 0.91301 0.02899 0.42801 0.90201 0.175 0.217 \n",
      "      c1    c1d     c2     c3    c4     c5 \n",
      "w 0.9994 0.0001 0.0003 0.0001     0 0.0001 \n",
      "lambda\t0.00039\n"
     ]
    }
   ],
   "source": [
    "inst.model2.bpt.display()\n",
    "inst.model2.cv.display()\n",
    "print(\"lambda\\t%.7s\" % inst.model2.lbda) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 : validate the learning of the random model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the rate of validation of the model (which is the percentage for the learned model to find the good classifications compared to assignments given by the original model) regarding the learning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation rate : 1.000000\n"
     ]
    }
   ],
   "source": [
    "ca_v,cag_v = inst.eval_model_validation() # calculating the validation rate\n",
    "print(\"validation rate : %f\" % ca_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also draw the confusion matrix of the validation phase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cat2 cat1 \n",
      "cat2   49    0 \n",
      "cat1    0   51 \n"
     ]
    }
   ],
   "source": [
    "matrix = compute_confusion_matrix(inst.aa, inst.aa_learned, inst.model.categories) # construction of the confusion matrix\n",
    "print_confusion_matrix(matrix, inst.model.categories) # printing the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7 : test the learned algorithm on a benchmarch of alternatives examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogously, we can calculate the test rate (which is the percentage for the learned model to find the good classification compared to right assignments given by the original model) regarding a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rate : 0.941000\n"
     ]
    }
   ],
   "source": [
    "ao_tests,al_tests,ca_t,cag_t = inst.eval_model_test()\n",
    "print(\"test rate : %f\" % ca_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8 : show the important results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show the final results, we need to achieve all the tests ; in fact, until now we only compute one learned model. Therefore, it is important to carry out the runnings and yield *nb_models* learned models. To do so, we can straightforwardly execute :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.run_mrsort_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, all the tests are done and we have also generated a csv file summarizing the tests and giving details of each one. This file is found on the directory *rand_valid_test_na100_nca2_ncr5-0_dupl1* visible from the root directory of this notebook. The file name begins with \"valid_test_dupl....\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another csv file is the file that contains more compact data facilitating the drawing of different plots. This file is generated with the command line :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.report_plot_results_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It yields a csv file, which name begins with \"plot_results....\" in the same directory as the previous file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final function of this section is the function that ouputs a instance of the learning algorithm (criteria, categories, performance tables and assignments, all codified in a customized syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook/rand_valid_test_na100_nca2_ncr5-0_dupl1//osomcda_rand-100-2-5-1-20191029-115742.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst.build_osomcda_instance_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output file is also in the previous directory as the previous files."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use what have been done in the previous section as a unit test, and then we will repeat it several times, varying different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give here the call of a unit test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.learning_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read in advance the implementation of the functions of this part, we run :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "run oso-pymcda/apps/learning_random_models_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of the series of tests, some parameters must be set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_categories = 2 #fixed\n",
    "nb_criteria = 6\n",
    "\n",
    "ticks_criteria = list(range(0,nb_criteria+1,2)) # ticks on plots results representing the number fo criteria\n",
    "ticks_alternatives = list(range(50,200,50)) # ticks on plots results representing the number of alternatives\n",
    "\n",
    "nb_tests = 10000\n",
    "nb_models = 10\n",
    "\n",
    "#Parameters of the metaheuristic MRSort\n",
    "meta_l = 10\n",
    "meta_ll = 10\n",
    "meta_nb_models = 10\n",
    "directory = DATADIR\n",
    "output_dir = DATADIR + \"/learning_results_plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four variables have not been explained yet. These are :\n",
    "   * *ticks_criteria* : the range of the ticks values corresponding to the number of duplicated criteria. One tick corresponds to a unit test made on a given number of duplicated criteria.\n",
    "   * *ticks_alternatives* : the range of the ticks values of the number of alternatives taken into consideration in the multiple test process. One tick represents a number of alternatives taken into account on a unit test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply now a function that will compute series of unit tests according to the range of values of the parameters given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined a function (***exec_all_tests***) to execute this bunch of tests with different experiment protocols. It runs each unit test with a different random model and different set of alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's construct an instance of that sort and then run ***exec_all_tests*** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_instance = MRSortLearningResults(directory, output_dir, nb_categories, nb_criteria,ticks_criteria,ticks_alternatives, \\\n",
    "                nb_tests, nb_models, meta_l, meta_ll, meta_nb_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... unit test nb_alternatives = 50, nb_duplicated_criteria = 0\n",
      " ... unit test nb_alternatives = 50, nb_duplicated_criteria = 2\n",
      " ... unit test nb_alternatives = 50, nb_duplicated_criteria = 4\n",
      " ... unit test nb_alternatives = 50, nb_duplicated_criteria = 6\n",
      " ... unit test nb_alternatives = 100, nb_duplicated_criteria = 0\n",
      " ... unit test nb_alternatives = 100, nb_duplicated_criteria = 2\n",
      " ... unit test nb_alternatives = 100, nb_duplicated_criteria = 4\n",
      " ... unit test nb_alternatives = 100, nb_duplicated_criteria = 6\n",
      " ... unit test nb_alternatives = 150, nb_duplicated_criteria = 0\n",
      " ... unit test nb_alternatives = 150, nb_duplicated_criteria = 2\n",
      " ... unit test nb_alternatives = 150, nb_duplicated_criteria = 4\n",
      " ... unit test nb_alternatives = 150, nb_duplicated_criteria = 6\n"
     ]
    }
   ],
   "source": [
    "tests_instance.exec_all_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are compiled into several folders beginning by \"rand_valid_test...\". Each of them contains the result of a single unit test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally and after having the results, we can run the program that shows the graphical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_instance.plot_all_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a folder named \"learning_results_plots\" containing different comparative plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four types of plots subdivized as follows:\n",
    "   * *computational_time* : in this folder, we draw the evolution of the execution time of a running of the learning process depending on 2 factors : the number of alternatives and the number of duplicated criteria (those criteria we want to learn the preference direction from). Following the first factor, we have individual plots with fixed number of duplicated criteria (time_nb_alternatives_dupl...), as well as a summary plot (time_nb_alternatives_dupl_all). Following the second factor, we also have individual plots with the number of alternatives fixed (time_dupl_crit_na...), as well as a summary plot (time_dupl_crit_na_all).\n",
    "   * *validation_CA* : these plots are about the percentage of restoration of the learning set by the learned model compared to the original model. The arrangement of the plots in 2 factors is the same as for *computational_time* (the first point).\n",
    "   * *tests_CA* : these plots concern the percentage of restoration of the learning test by the learned model compared to the original model.The arrangement of the plots in 2 factors is the same as for *computational_time* (the first point).\n",
    "   * *restitution* : these plots concern the percentage of the ability to deduce the preference directions of the duplicated criteria. [For example, considering one criteria and its duplicate, we assume that the preference direction is found if in a case of maximization of this criteria, its duplicate (which is a criteria that incite to minimize) is found to be equal to 0. In fact, this duplicate isn't taken into account by the model.] The arrangement of the plots in 2 factors is the same as for *computational_time* (the first point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
