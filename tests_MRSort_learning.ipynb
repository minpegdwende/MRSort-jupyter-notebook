{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the parameters of a MRSort model using the metaheuristic algorithm (oso-pymcda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metaheuristic code at our disposal comes from github (https://github.com/oso/pymcda) developped by Olivier Sobrie). In addition to this code, we took into account mainly these adaptations : the learning a MRSort model from \"a duplicated data set\", the generation of statistic plots on the learning results. The code originally in Python 2 has been upgraded to some extent to Python 3. This code is located in the \"oso-pymcda/\" directory, which is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before digging into the code, here are some requirements to have : \n",
    "   * The library matplotlib.pyplot need to be installed. This can be done with the command line below (preferably using pip  - that can be also installed following the instructions of this link : https://pip.pypa.io/en/stable/installing/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.16.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Set up the Python API of CPLEX : https://www.ibm.com/support/knowledgecenter/SSSA5P_12.9.0/ilog.odms.cplex.help/CPLEX/GettingStarted/topics/set_up/Python_setup.html and follow the steps. The manual (here https://www.ibm.com/support/knowledgecenter/SSSA5P_12.9.0/ilog.odms.cplex.help/CPLEX/Python/topics/cplex_python_overview.html can help also.)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set the global variable *DATADIR* so that it contains the right path from the root to this working directory  **MRSort-jupyter-notebook** . Here an example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATADIR=/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook\n"
     ]
    }
   ],
   "source": [
    "%env DATADIR /Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code gathers mainly 2 parts : \n",
    "   * the first component on the generation, learning and tests of a parametered MRSort model (one running of the learning algorithm followed by tests),\n",
    "   * the second component on the compilation of series of parametered MRSort runnings and the output of interesting statistic plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to move to our working environment and run the main file in order to keep in memory the implementations of functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run oso-pymcda/apps/random_model_generation_msjp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, to achieve our goal we follow these steps : \n",
    "   * <u>Step 1</u> : initialize the required parameters,\n",
    "   * <u>Step 2</u> : generate a new random MRSort model (profile, weights, threshold),\n",
    "   * <u>Step 3</u> : generate randomly a set of alternatives and performance table,\n",
    "   * <u>Step 4</u> : assign categories to these alternatives to yield a learning set,\n",
    "   * <u>Step 5</u> : run the MRSort metaheuristic learning algorithm,\n",
    "   * <u>Step 6</u> : validate the learning of the random model (% of classification \"initial model VS learned model\" on the learning set)\n",
    "   * <u>Step 7</u> : test the learned algorithm on a benchmarch of alternatives examples\n",
    "   * <u>Step 8</u> : show the important results (summarized also in a csv file)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : initialize the required parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we initialize the parameters of one running for the learning algorithm. Respectively, we have : \n",
    "   * *nb_categories* : the number of categories (classes)\n",
    "   * *nb_criteria* : the number of criteria taken in consideration of the MCDA problem\n",
    "   * *nb_alternatives* : the number of alternatives (for the learning set)\n",
    "   * *dir_criteria* : the list of order/direction on preferences of the criteria  (1 for a criteria to maximize)\n",
    "   * *l_dupl_criteria* : the list of criteria (indices) to duplicate during the learning process\n",
    "   * *nb_tests* : the number of tests (number of alternatives) to carry out in order to compare the performance of the learned model regarding the initial model\n",
    "   * *nb_models* : the number of models that independantly learn during one running of the learning algorithm\n",
    "   * *meta_l* : the number of iteration of the metaheuristic algorithm (outer loop)\n",
    "   * *meta_ll* : the number of iteration of the metaheuristic algorithm (inner loop)\n",
    "   * *meta_nb_models* : the number of models (population) handled by the metaheuristic (evolutionary) algorithm during the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_categories = 2 # fixed\n",
    "nb_criteria = 5\n",
    "nb_alternatives = 100\n",
    "dir_criteria = [1]*nb_criteria # fixed to 1 for all criteria\n",
    "l_dupl_criteria = list(range(nb_criteria))[:1]\n",
    "\n",
    "# parameters of test\n",
    "nb_tests = 10000\n",
    "nb_models = 10\n",
    "\n",
    "# parameters of the metaheuristic MRSort\n",
    "meta_l = 10\n",
    "meta_ll = 10\n",
    "meta_nb_models = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create an instance of the one running of the learning algorithm as follows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = RandMRSortLearning(nb_alternatives, nb_categories, \n",
    "        nb_criteria, dir_criteria, l_dupl_criteria, \n",
    "        nb_tests, nb_models, meta_l, meta_ll, meta_nb_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 to 4 : generate a new random MRSort model, alternatives and assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here 3 steps are performs one after the other in the same function. We generate a new random MRSort, then we generate alternatives, and finally we assign these alternatives in 2 categories regarding the MRSort rule of the given model. In addition to these 3 operations, we introduce a coefficient that enable us to control the balance between the set of alternatives (number of alternatives) sorted in the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.generate_random_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look on the model that have been generated :\n",
    "   * generated parameters of the model MRSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c1    c2    c3    c4    c5 \n",
      "b1 0.148 0.541 0.352 0.269 0.061 \n"
     ]
    }
   ],
   "source": [
    "inst.model.bpt.display() # display the limit profile of the random model b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c1    c2    c3    c4    c5 \n",
      "w 0.319 0.087 0.012 0.478 0.103 \n"
     ]
    }
   ],
   "source": [
    "inst.model.cv.display() # display the weights of each criteria of the model w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda\t0.867\n"
     ]
    }
   ],
   "source": [
    "print(\"lambda\\t%.7s\" % inst.model.lbda) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * performance table of generated alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        c1    c2    c3    c4    c5 \n",
      "a1   0.697 0.274 0.829  0.97 0.332 \n",
      "a10  0.507 0.982 0.895  0.51 0.524 \n",
      "a100 0.887 0.547 0.084 0.113 0.723 \n",
      "a11  0.203 0.054 0.091 0.432 0.496 \n",
      "a12   0.92 0.494 0.935 0.893 0.971 \n",
      "a13  0.467 0.672 0.482 0.113 0.092 \n",
      "a14  0.147 0.599 0.544 0.892 0.838 \n",
      "a15  0.589 0.024 0.399 0.285 0.903 \n",
      "a16   0.75 0.526 0.824 0.076 0.471 \n",
      "a17  0.611 0.678 0.295 0.295 0.662 \n",
      "a18  0.515 0.503 0.695 0.441 0.726 \n",
      "a19  0.815 0.045  0.89 0.948 0.713 \n",
      "a2   0.183 0.495 0.428 0.644 0.137 \n",
      "a20  0.387 0.882 0.026 0.962 0.899 \n",
      "a21  0.429 0.753 0.298   0.7 0.051 \n",
      "a22  0.727 0.533  0.94 0.262 0.452 \n",
      "a23  0.064 0.617 0.746  0.09 0.459 \n",
      "a24   0.47 0.717 0.323 0.557 0.453 \n",
      "a25  0.082 0.866 0.863 0.224 0.299 \n",
      "a26  0.968 0.491 0.028 0.257 0.449 \n",
      "a27  0.954 0.415 0.747  0.74 0.466 \n",
      "a28  0.138 0.902 0.399 0.496 0.702 \n",
      "a29  0.391 0.904 0.788 0.394 0.408 \n",
      "a3   0.952 0.723 0.052 0.119 0.766 \n",
      "a30  0.253 0.342 0.033  0.77 0.407 \n",
      "a31  0.681 0.382 0.488  0.52 0.377 \n",
      "a32  0.105 0.927 0.218 0.739 0.434 \n",
      "a33  0.783 0.871 0.544 0.728 0.572 \n",
      "a34  0.492 0.254 0.224 0.195 0.759 \n",
      "a35  0.981 0.501  0.87 0.269 0.483 \n",
      "a36  0.912 0.422 0.931  0.93 0.404 \n",
      "a37  0.007 0.035 0.136 0.329 0.072 \n",
      "a38  0.304 0.568 0.922 0.815 0.392 \n",
      "a39  0.791 0.306 0.837 0.913 0.837 \n",
      "a4    0.54 0.637 0.902 0.506 0.071 \n",
      "a40  0.577 0.498 0.725 0.104 0.891 \n",
      "a41  0.379 0.838 0.956 0.225 0.778 \n",
      "a42  0.336 0.354  0.61 0.985 0.578 \n",
      "a43  0.188 0.122 0.303 0.158 0.144 \n",
      "a44   0.14 0.028 0.217 0.853 0.119 \n",
      "a45  0.709 0.788 0.241 0.296 0.754 \n",
      "a46  0.265 0.429 0.895 0.386 0.831 \n",
      "a47  0.851 0.137 0.886 0.902 0.328 \n",
      "a48  0.412 0.471 0.404 0.743 0.992 \n",
      "a49  0.363 0.119 0.217  0.32 0.376 \n",
      "a5   0.739 0.464 0.154 0.166   0.1 \n",
      "a50  0.165 0.324 0.655  0.43 0.536 \n",
      "a51   0.19 0.194 0.792 0.065 0.203 \n",
      "a52  0.491 0.595 0.474 0.622 0.114 \n",
      "a53  0.064 0.353 0.296 0.534 0.732 \n",
      "a54  0.728 0.651 0.502 0.451 0.126 \n",
      "a55  0.062  0.82 0.409 0.203 0.512 \n",
      "a56  0.105 0.052 0.577 0.598 0.555 \n",
      "a57  0.584 0.005 0.076 0.073 0.636 \n",
      "a58  0.257 0.554 0.187 0.807 0.608 \n",
      "a59  0.961 0.982 0.741 0.841 0.034 \n",
      "a6   0.704 0.063  0.59 0.144 0.774 \n",
      "a60  0.411 0.294  0.23 0.065 0.338 \n",
      "a61  0.201 0.938 0.592 0.397 0.914 \n",
      "a62  0.314 0.731 0.445 0.724 0.587 \n",
      "a63  0.873 0.209 0.984 0.054 0.913 \n",
      "a64  0.326 0.354 0.875 0.231 0.954 \n",
      "a65  0.213 0.617 0.771 0.924 0.224 \n",
      "a66  0.386 0.255 0.566  0.71 0.417 \n",
      "a67  0.012 0.809 0.267 0.582  0.02 \n",
      "a68  0.816 0.874 0.416 0.781 0.058 \n",
      "a69  0.601 0.824 0.717 0.288 0.676 \n",
      "a7    0.68 0.082 0.188 0.201 0.629 \n",
      "a70  0.428 0.944 0.893 0.469 0.318 \n",
      "a71  0.878 0.255 0.138 0.296   0.6 \n",
      "a72   0.44 0.082 0.941 0.484 0.503 \n",
      "a73  0.964  0.72 0.148 0.859 0.132 \n",
      "a74  0.055  0.49 0.847 0.531 0.366 \n",
      "a75  0.146 0.984 0.132 0.211 0.402 \n",
      "a76  0.333 0.208 0.106 0.235 0.407 \n",
      "a77  0.643 0.314 0.846 0.393 0.949 \n",
      "a78   0.66 0.018 0.556 0.751 0.941 \n",
      "a79   0.77 0.713 0.649 0.659 0.059 \n",
      "a8   0.016 0.121 0.446 0.644 0.904 \n",
      "a80  0.613 0.553 0.052 0.169 0.753 \n",
      "a81  0.232 0.194  0.53 0.696 0.943 \n",
      "a82  0.596 0.494 0.048 0.464 0.687 \n",
      "a83  0.192 0.027 0.869  0.73 0.302 \n",
      "a84  0.936 0.167 0.979 0.213 0.615 \n",
      "a85   0.34 0.094 0.406  0.06 0.968 \n",
      "a86  0.312  0.25 0.727 0.263 0.177 \n",
      "a87  0.697 0.595  0.28 0.677 0.008 \n",
      "a88  0.284 0.878 0.807 0.768 0.548 \n",
      "a89  0.565 0.169 0.366 0.203 0.315 \n",
      "a9   0.645  0.93 0.814 0.375 0.485 \n",
      "a90  0.568 0.507 0.425 0.425 0.564 \n",
      "a91   0.32 0.973 0.451  0.45 0.162 \n",
      "a92  0.482 0.854 0.677 0.036 0.441 \n",
      "a93   0.09 0.883 0.268 0.027 0.042 \n",
      "a94   0.17 0.452 0.407 0.567 0.243 \n",
      "a95   0.94  0.78 0.378 0.804 0.838 \n",
      "a96  0.921 0.115 0.683 0.658 0.661 \n",
      "a97  0.192 0.568 0.449 0.855 0.313 \n",
      "a98  0.723 0.942 0.709 0.824 0.499 \n",
      "a99  0.712 0.477 0.389 0.596 0.294 \n"
     ]
    }
   ],
   "source": [
    "inst.pt.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * the result of the assignment of alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     category\n",
      "a1       cat1\n",
      "a10      cat1\n",
      "a100     cat2\n",
      "a11      cat1\n",
      "a12      cat1\n",
      "a13      cat2\n",
      "a14      cat2\n",
      "a15      cat1\n",
      "a16      cat2\n",
      "a17      cat1\n",
      "a18      cat1\n",
      "a19      cat1\n",
      "a2       cat1\n",
      "a20      cat1\n",
      "a21      cat1\n",
      "a22      cat2\n",
      "a23      cat2\n",
      "a24      cat1\n",
      "a25      cat2\n",
      "a26      cat2\n",
      "a27      cat1\n",
      "a28      cat2\n",
      "a29      cat1\n",
      "a3       cat2\n",
      "a30      cat1\n",
      "a31      cat1\n",
      "a32      cat2\n",
      "a33      cat1\n",
      "a34      cat2\n",
      "a35      cat1\n",
      "a36      cat1\n",
      "a37      cat2\n",
      "a38      cat1\n",
      "a39      cat1\n",
      "a4       cat1\n",
      "a40      cat2\n",
      "a41      cat2\n",
      "a42      cat1\n",
      "a43      cat2\n",
      "a44      cat2\n",
      "a45      cat1\n",
      "a46      cat1\n",
      "a47      cat1\n",
      "a48      cat1\n",
      "a49      cat1\n",
      "a5       cat2\n",
      "a50      cat1\n",
      "a51      cat2\n",
      "a52      cat1\n",
      "a53      cat2\n",
      "a54      cat1\n",
      "a55      cat2\n",
      "a56      cat2\n",
      "a57      cat2\n",
      "a58      cat1\n",
      "a59      cat1\n",
      "a6       cat2\n",
      "a60      cat2\n",
      "a61      cat1\n",
      "a62      cat1\n",
      "a63      cat2\n",
      "a64      cat2\n",
      "a65      cat1\n",
      "a66      cat1\n",
      "a67      cat2\n",
      "a68      cat1\n",
      "a69      cat1\n",
      "a7       cat2\n",
      "a70      cat1\n",
      "a71      cat1\n",
      "a72      cat1\n",
      "a73      cat1\n",
      "a74      cat2\n",
      "a75      cat2\n",
      "a76      cat2\n",
      "a77      cat1\n",
      "a78      cat1\n",
      "a79      cat1\n",
      "a8       cat2\n",
      "a80      cat2\n",
      "a81      cat1\n",
      "a82      cat1\n",
      "a83      cat1\n",
      "a84      cat2\n",
      "a85      cat2\n",
      "a86      cat2\n",
      "a87      cat1\n",
      "a88      cat1\n",
      "a89      cat2\n",
      "a9       cat1\n",
      "a90      cat1\n",
      "a91      cat1\n",
      "a92      cat2\n",
      "a93      cat2\n",
      "a94      cat1\n",
      "a95      cat1\n",
      "a96      cat1\n",
      "a97      cat1\n",
      "a98      cat1\n",
      "a99      cat1\n"
     ]
    }
   ],
   "source": [
    "inst.aa.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: run the MRSort metaheuristic learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following step represents one model iteration of the metaheuristic algorithm. This iteration learns with a single model the initial model from the previous learning set (performance table and assignments of alternatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) : 0.097778\n"
     ]
    }
   ],
   "source": [
    "inst.num_model = 0 # initialization of the position of the model that is currently learning\n",
    "execution_time = inst.run_mrsort()\n",
    "print(\"Time (s) : %f\" % execution_time) # computational time of the running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the parameters of the model learned :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        c1   c1d    c2      c3      c4    c5 \n",
      "b1 0.14701 0.886 0.379 0.97901 0.26301 0.707 \n",
      "      c1   c1d    c2    c3     c4    c5 \n",
      "w 0.0001     0     0     0 0.9999     0 \n",
      "lambda\t1.0\n"
     ]
    }
   ],
   "source": [
    "inst.model2.bpt.display()\n",
    "inst.model2.cv.display()\n",
    "print(\"lambda\\t%.7s\" % inst.model2.lbda) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 : validate the learning of the random model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the rate of validation of the model (which is the percentage for the learned model to find the good classifications compared to assignments given by the original model) regarding the learning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation rate : 1.000000\n"
     ]
    }
   ],
   "source": [
    "ca_v,cag_v = inst.eval_model_validation() # calculating the validation rate\n",
    "print(\"validation rate : %f\" % ca_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also draw the confusion matrix of the validation phase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cat2 cat1 \n",
      "cat2   40    0 \n",
      "cat1    0   60 \n"
     ]
    }
   ],
   "source": [
    "matrix = compute_confusion_matrix(inst.aa, inst.aa_learned, inst.model.categories) # construction of the confusion matrix\n",
    "print_confusion_matrix(matrix, inst.model.categories) # printing the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7 : test the learned algorithm on a benchmarch of alternatives examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogously, we can calculate the test rate (which is the percentage for the learned model to find the good classification compared to right assignments given by the original model) regarding a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rate : 0.973800\n"
     ]
    }
   ],
   "source": [
    "ao_tests,al_tests,ca_t,cag_t = inst.eval_model_test()\n",
    "print(\"test rate : %f\" % ca_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8 : show the important results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to show the final results, we need to achieve all the tests ; in fact, until now we only compute one learned model. Therefore, it is important to carry out the runnings and yield *nb_models* learned models. To do so, we can straightforwardly execute :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.run_mrsort_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, all the tests are done and we have also generated a csv file summarizing the tests and giving details of each one. This file is found on the directory *rand_valid_test_na100_nca2_ncr5-0_dupl1* visible from the root directory of this notebook. The file name begins with \"valid_test_dupl....\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another csv file is the file that contains more compact data facilitating the drawing of different plots. This file is generated with the command line :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.report_plot_results_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It yields a csv file, which name begins with \"plot_results....\" in the same directory as the previous file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final function of this section is the function that ouputs a instance of the learning algorithm (criteria, categories, performance tables and assignments, all codified in a customized syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook/rand_valid_test_na100_nca2_ncr5-0_dupl1//osomcda_rand-100-2-5-1-20191015-164258.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst.build_osomcda_instance_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output file is also in the previous directory as the previous files."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The second component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use what have been done in the previous section as a unit test, and then we will repeat it several times, varying different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give here the call of a unit test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.learning_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to read in advance the implementation of the functions of this part, we run :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "run oso-pymcda/apps/learning_random_models_results.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of the series of tests, some parameters must be set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_categories = 2 #fixed\n",
    "nb_criteria = 6\n",
    "\n",
    "ticks_criteria = list(range(0,nb_criteria+1,2)) # ticks on plots results representing the number fo criteria\n",
    "ticks_alternatives = list(range(50,200,50)) # ticks on plots results representing the number of alternatives\n",
    "\n",
    "nb_tests = 10000\n",
    "nb_models = 10\n",
    "\n",
    "#Parameters of the metaheuristic MRSort\n",
    "meta_l = 10\n",
    "meta_ll = 10\n",
    "meta_nb_models = 10\n",
    "directory = DATADIR\n",
    "output_dir = DATADIR + \"/learning_results_plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four variables have not been explained yet. These are :\n",
    "   * *ticks_criteria* : the range of the ticks values corresponding to the number of duplicated criteria. One tick corresponds to a unit test made on a given number of duplicated criteria.\n",
    "   * *ticks_alternatives* : the range of the ticks values of the number of alternatives taken into consideration in the multiple test process. One tick represents a number of alternatives taken into account on a unit test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply now a function that will compute series of unit tests according to the range of values of the parameters given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined 3 types of functions to execute this bunch of tests with different experiment protocols :\n",
    "   * ***exec_all_tests*** : it runs each unit test with a different random model and different set of alternatives.\n",
    "   * **exec_all_tests2** : it runs each unit test with the same random model (same parameters), but with different set of alternatives.\n",
    "   * **exec_all_tests3**  : it runs each unit test with the same random model and by progressively incrementing the sets of alternatives. For instance, after running a unit test with <u>n</u> alternatives, this procedure will keep these alternatives and add <u>n</u> new ones for the next unit test resulting a unit test with <u>2n</u> alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's construct an instance of that sort and then run ***exec_all_tests*** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_instance = MRSortLearningResults(directory, output_dir, nb_categories, nb_criteria,ticks_criteria,ticks_alternatives, \\\n",
    "                nb_tests, nb_models, meta_l, meta_ll, meta_nb_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... unit test nb_alternatives = 50, nb_duplicated_criteria = 0\n",
      " ... unit test nb_alternatives = 50, nb_duplicated_criteria = 2\n",
      " ... unit test nb_alternatives = 50, nb_duplicated_criteria = 4\n",
      " ... unit test nb_alternatives = 50, nb_duplicated_criteria = 6\n",
      " ... unit test nb_alternatives = 100, nb_duplicated_criteria = 0\n",
      " ... unit test nb_alternatives = 100, nb_duplicated_criteria = 2\n",
      " ... unit test nb_alternatives = 100, nb_duplicated_criteria = 4\n",
      " ... unit test nb_alternatives = 100, nb_duplicated_criteria = 6\n",
      " ... unit test nb_alternatives = 150, nb_duplicated_criteria = 0\n",
      " ... unit test nb_alternatives = 150, nb_duplicated_criteria = 2\n",
      " ... unit test nb_alternatives = 150, nb_duplicated_criteria = 4\n",
      " ... unit test nb_alternatives = 150, nb_duplicated_criteria = 6\n"
     ]
    }
   ],
   "source": [
    "tests_instance.exec_all_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are compiled into several folders beginning by \"rand_valid_test...\". Each of them contains the result of a single unit test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally and after having the results, we can run the program that shows the graphical representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_instance.plot_all_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a folder named \"learning_results_plots\" containing different comparative plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
