{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the parameters of a MR-Sort model using a readapted version of an existing metaheuristic algorithm (oso-pymcda) in context of unknown preference directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intend in this document to brievely describe our version of a metaheuristic algorithm for the learning of MR-Sort model parameters without knowing in advance the preference directions of some criteria.\n",
    "\n",
    "The initial metaheuristic algorithm at our disposal comes from github (https://github.com/oso/pymcda) developped by Olivier Sobrie). This algorithm is the starting point on which we present our approach.\n",
    "\n",
    "More specifically, this proposition - that can be seen as an extension of the existing metaheuristic - integrate more parameters, in particular preference directions on each criteria. We also include the computation preference direction restoration rate accuracy, as well as the generation of statistic plots on the learning results. \n",
    "\n",
    "The code originally in Python 2 has been upgraded to some extent to Python 3 and is located in the \"oso-pymcda/\" directory, which is in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpful articles on MRSort models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to grasp the metaheuristic that is used in this notebook and have a overview on the methodology of MCDA, we give here below some useful related articles :\n",
    "   * [Learning monotone preferences using a majority rule sorting model](papers/Sobrie_Mousseau_Pirlot.pdf) (in particular, this explains with details the procedure of the metaheuristic)\n",
    "   * [Learning the Parameters of a Multiple Criteria Sorting Method Based on a Majority Rule](papers/Leroy_Mousseau_Pirlot.pdf)\n",
    "   * [A new decision support model for preanesthetic evaluation](papers/Sobrie_and_al.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before digging into the code, here are some requirements to have : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The version of Python used for this notebook is 3.7. Please check if you have the right version with this command on a terminal : *python --version* . If not, you can download this version on https://www.python.org/downloads/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * You may need to download Anaconda3 (you will find here the complete procedure : https://docs.anaconda.com/anaconda/install/mac-os/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The library matplotlib.pyplot need to be installed. This can be done with the command line below (preferably using pip  - that can be also installed following the instructions of this link : https://pip.pypa.io/en/stable/installing/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.10.0 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.16.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: six in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Download CPLEX Optimization Studio. Go to https://www.ibm.com/products/ilog-cplex-optimization-studio (choose the student/teacher free edition)  and follow the steps until the download of the \"ILOG CPLEX Optimization Studio\" following your operating system. The CPLEX version used in this notebook is 12.9. You may have to create a IBMid account. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Then, look at instructions in the ReadMe file of the CPLEX directory that has been created in the Applications directory. In particular, it may require that you update your Java runtime application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * Open also the ReadMe file in the python directory of the CPLEX directory. Execute this command line on the terminal : *pip install docplex*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * In order to set up the CPLEX Python API, follow instructions here : https://www.ibm.com/support/knowledgecenter/SSSA5P_12.9.0/ilog.odms.cplex.help/CPLEX/GettingStarted/topics/set_up/Python_setup.html. In the same directory as previously, execute the command line on the terminal  : *python setup.py install*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Set the environment variable PYTHONPATH on the terminal so that it may contains the path from the root folder to \"cplex\" via \"Anaconda3\" and another path from the \"Applications\" folder to \"cplex\". Here is an example : *export PYTHONPATH=$PYTHONPATH:/Users/pegdwendeminoungou/anaconda3/lib/python3.7/site-packages/cplex:/Applications/CPLEX_Studio129/cplex*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Any help could be found here : https://www.ibm.com/support/knowledgecenter/SSSA5P_12.9.0/ilog.odms.studio.help/Optimization_Studio/topics/COS_home.html\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set the global variable *DATADIR* so that it contains the right path from the root to this working directory  **MRSort-jupyter-notebook** . Here an example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATADIR=/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook\n"
     ]
    }
   ],
   "source": [
    "%env DATADIR /Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description of the metaheuristic for learning preference directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated before, our approach is based on a evolutionrary algorithm.\n",
    "It consist in the generation and evolution of heterogeneous models (models with both increasing and decreasing preference directions on some criteria) in the population.\n",
    "The goal of this readaptation is to foster the evolution of good models, those on which criteria possess the true preference directions.\n",
    "\n",
    "The implementation relies on a 3 axes : the mechanism of generation and renewal of the population of model, the core strategy of the method acting on model weights and profiles, and finally the decision rule on the selection of the yielded model, as well as learned preference directions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code contain mainly 2 parts : \n",
    "   * the first component is about the generation and learning of one parameterized MRSort model (one running of the learning algorithm followed by tests),\n",
    "   * the second component is about the compilation of series of parameterized MRSort runnings and the output of interesting statistic plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, in order to load what is needed in this part, let us excute the following command line :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run oso-pymcda/apps/random_model_generation_msjp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we progressively follow  these steps : \n",
    "   * <u>Step 1</u> : initialize both problem and algorithm parameters,\n",
    "   * <u>Step 2</u> : generate a new random MR-Sort model (profile, weights, threshold) => this is the ground truth model,\n",
    "   * <u>Step 3</u> : generate randomly a set of alternatives and performance table,\n",
    "   * <u>Step 4</u> : assign categories to these alternatives to yield a learning set in accordance with the problem addressed,\n",
    "   * <u>Step 5</u> : run the MR-Sort the readapted metaheuristic algorithm,\n",
    "   * <u>Step 6</u> : validate the learning of the model (% of classification accuracy (CA) of the learned model compared to the initial model on the learning set, restoration rate of preference directions )\n",
    "   * <u>Step 7</u> : test the learned algorithm on a benchmarch of alternatives examples\n",
    "   * <u>Step 8</u> : display the important results (summarized also in a csv file)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 : initialize the required parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we initialize the parameters for one running of the learning algorithm. \n",
    "First, we have the problem parameters : \n",
    "   * *nb_categories* : the number of categories (classes)\n",
    "   * *nb_criteria* : the number of criteria taken in consideration in the problem\n",
    "   * *nb_alternatives* : the number of alternatives in the learning set\n",
    "   * *dir_criteria* : the list of preference directions of the original model\n",
    "   * *nb_unk_criteria* : the number of criteria with unknown preference directions\n",
    "   * *l_dupl_criteria* : the list of criteria (indices) with unknown preference directions\n",
    "   * *nb_tests* : the number of alternatives taken into account in the test set\n",
    "   * *nb_models* : the number of models that independantly learn during one running of the learning algorithm\n",
    "   * *meta_l* : the number of iteration of the metaheuristic algorithm (outer loop)\n",
    "   * *meta_ll* : the number of iteration of the metaheuristic algorithm (inner loop)\n",
    "   * *meta_nb_models* : the number of models (population) handled by the metaheuristic (evolutionary) algorithm during the learning process\n",
    "\n",
    "Let's notice that *nb_unk_criteria* must be smaller than *nb_criteria*.\n",
    "By default the criteria whose preference directions are known, have an increasing preference direction.\n",
    "By default the criteria whose preference directions are unknown, are the *nb_unk_criteria* first criteria (the list of criteria starting with c1, c2, c3, ....).\n",
    "Then, we have the algorithm specific parameters:\n",
    "\n",
    "   * *version_meta* : the version of implementation\n",
    "   * *renewal_method* : the method used to renew the population depending on preference directions distribution.  \n",
    "   * *renewal_models* : the first element of the tuple is the renewal rate, and the second is the coefficient rate (must not be both null or both non null)\n",
    "   * *strategy* : the first element of the tuple is the starting lower bound on weights, and the second is the starting percentile for the profile interval restriction (on criteria with unknown preference directions)\n",
    "   * *stopping_condition* : it corresponds to the maximal number of iterations\n",
    "   * *decision_rule* : it corresponds to the rank of the chosen model among learned models of the population (sorted according to their fitness).\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_categories = 2 # fixed\n",
    "nb_criteria = 5\n",
    "nb_alternatives = 50\n",
    "dir_criteria = [1]*nb_criteria # fixed to 1 for all criteria\n",
    "nb_unk_criteria = 1\n",
    "l_dupl_criteria = list(range(nb_criteria))[:nb_unk_criteria]\n",
    "\n",
    "# test parameters\n",
    "nb_tests = 10000\n",
    "nb_models = 5\n",
    "\n",
    "# parameters of the metaheuristic MRSort\n",
    "meta_l = 30\n",
    "meta_ll = 20\n",
    "meta_nb_models = 50\n",
    "\n",
    "# additionnal parameters of the algorithm\n",
    "version_meta = 8 #fixed\n",
    "renewal_method = 2 #fixed\n",
    "renewal_models = (0,0.35)\n",
    "strategy = (0.2,25)\n",
    "stopping_condition = meta_l\n",
    "decision_rule = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create an instance of the one running of the learning algorithm as follows :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = RandMRSortLearning(nb_alternatives, nb_categories, nb_criteria, dir_criteria, l_dupl_criteria, \n",
    "                          nb_tests, nb_models, meta_l, meta_ll, meta_nb_models,renewal_method = renewal_method,\n",
    "                          renewal_models = renewal_models, strategy = strategy,stopping_condition = stopping_condition, \n",
    "                          decision_rule = decision_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 to 4 : generate a new random MRSort model, alternatives and assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here 3 steps are performed one after the other in the same function. We generate a new random MRSort, then we generate alternatives, and finally we assign these alternatives in 2 categories regarding the MRSort rule on the given model. In addition to these 3 operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.generate_random_instance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look on the model that have been generated :\n",
    "   * generated parameters of the model MRSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      c1    c2    c3    c4    c5 \n",
      "b1 0.491 0.781 0.472 0.303 0.599 \n"
     ]
    }
   ],
   "source": [
    "inst.model.bpt.display() # display the limit profile of the random model b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     c1    c2    c3    c4    c5 \n",
      "w  0.14 0.085  0.08 0.448 0.247 \n"
     ]
    }
   ],
   "source": [
    "inst.model.cv.display() # display the weights of each criteria of the model w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority threshold (lambda) : \t0.672\n"
     ]
    }
   ],
   "source": [
    "print(\"Majority threshold (lambda) : \\t%.7s\" % inst.model.lbda) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * performance table of generated alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       c1    c2    c3    c4    c5 \n",
      "a1  0.396 0.795 0.084   0.3 0.433 \n",
      "a10 0.917 0.175 0.791 0.248 0.011 \n",
      "a11 0.709 0.993 0.598 0.749 0.887 \n",
      "a12 0.451 0.204 0.188 0.601 0.643 \n",
      "a13 0.966 0.873 0.407 0.698 0.109 \n",
      "a14 0.093 0.005 0.348 0.629 0.173 \n",
      "a15 0.002 0.962 0.063 0.649 0.942 \n",
      "a16 0.071   0.3 0.681 0.825 0.665 \n",
      "a17 0.557 0.939 0.438 0.359 0.856 \n",
      "a18  0.97 0.832 0.272 0.661  0.54 \n",
      "a19 0.138 0.173  0.18  0.35 0.413 \n",
      "a2  0.762 0.897  0.33 0.671 0.086 \n",
      "a20 0.893 0.313 0.013 0.764 0.785 \n",
      "a21 0.655 0.613 0.312 0.812 0.889 \n",
      "a22 0.883 0.309 0.454 0.351 0.421 \n",
      "a23 0.676 0.885 0.281 0.215  0.03 \n",
      "a24 0.465 0.341 0.619 0.527 0.975 \n",
      "a25 0.042 0.232 0.315 0.616 0.291 \n",
      "a26 0.328 0.579 0.167 0.847 0.162 \n",
      "a27 0.149  0.12 0.726 0.599 0.521 \n",
      "a28 0.861 0.663 0.337  0.76 0.656 \n",
      "a29 0.552 0.976 0.761 0.723 0.659 \n",
      "a3  0.542 0.548 0.363 0.931 0.967 \n",
      "a30 0.874 0.713 0.453 0.462 0.689 \n",
      "a31 0.697 0.922 0.757 0.252 0.257 \n",
      "a32  0.04 0.557 0.565 0.927 0.403 \n",
      "a33 0.251 0.677  0.86 0.149 0.755 \n",
      "a34 0.105 0.163 0.922 0.813  0.18 \n",
      "a35  0.51 0.792 0.501 0.843 0.619 \n",
      "a36 0.978 0.211 0.483 0.011 0.606 \n",
      "a37 0.134 0.756 0.457 0.192 0.036 \n",
      "a38  0.03 0.934 0.419 0.647 0.591 \n",
      "a39 0.692 0.691 0.498 0.513 0.756 \n",
      "a4  0.085 0.283 0.473 0.545  0.86 \n",
      "a40  0.15 0.904 0.943 0.118 0.398 \n",
      "a41 0.096 0.998 0.488 0.347 0.881 \n",
      "a42 0.513 0.122 0.785 0.006 0.346 \n",
      "a43 0.424 0.744 0.494 0.153  0.13 \n",
      "a44 0.336 0.004 0.512 0.455 0.068 \n",
      "a45 0.452 0.904 0.592  0.68 0.287 \n",
      "a46 0.383 0.269 0.016  0.57  0.26 \n",
      "a47 0.449 0.884 0.191 0.844 0.842 \n",
      "a48 0.738 0.336 0.644 0.602 0.119 \n",
      "a49 0.296 0.202 0.016 0.571 0.567 \n",
      "a5  0.711 0.368 0.064 0.764 0.746 \n",
      "a50 0.189 0.594 0.396 0.081 0.702 \n",
      "a6  0.776 0.856 0.625 0.336 0.714 \n",
      "a7  0.354 0.137 0.843 0.439 0.605 \n",
      "a8  0.766 0.194 0.021 0.324 0.119 \n",
      "a9  0.999 0.034 0.465 0.477 0.039 \n"
     ]
    }
   ],
   "source": [
    "inst.pt.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * the result of the assignment of alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    category\n",
      "a1      cat1\n",
      "a10     cat1\n",
      "a11     cat2\n",
      "a12     cat2\n",
      "a13     cat2\n",
      "a14     cat1\n",
      "a15     cat2\n",
      "a16     cat2\n",
      "a17     cat2\n",
      "a18     cat2\n",
      "a19     cat1\n",
      "a2      cat2\n",
      "a20     cat2\n",
      "a21     cat2\n",
      "a22     cat1\n",
      "a23     cat1\n",
      "a24     cat2\n",
      "a25     cat1\n",
      "a26     cat1\n",
      "a27     cat1\n",
      "a28     cat2\n",
      "a29     cat2\n",
      "a3      cat2\n",
      "a30     cat2\n",
      "a31     cat1\n",
      "a32     cat1\n",
      "a33     cat1\n",
      "a34     cat1\n",
      "a35     cat2\n",
      "a36     cat1\n",
      "a37     cat1\n",
      "a38     cat1\n",
      "a39     cat2\n",
      "a4      cat2\n",
      "a40     cat1\n",
      "a41     cat2\n",
      "a42     cat1\n",
      "a43     cat1\n",
      "a44     cat1\n",
      "a45     cat1\n",
      "a46     cat1\n",
      "a47     cat2\n",
      "a48     cat1\n",
      "a49     cat1\n",
      "a5      cat2\n",
      "a50     cat1\n",
      "a6      cat2\n",
      "a7      cat2\n",
      "a8      cat1\n",
      "a9      cat1\n"
     ]
    }
   ],
   "source": [
    "inst.aa.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: run the MRSort metaheuristic learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following step represents one running of the metaheuristic algorithm. This execution learns a randomized model from a generated learning set (performance table and assignments of alternatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) : 12.393053\n"
     ]
    }
   ],
   "source": [
    "inst.num_model = 0 # the number of the current running\n",
    "execution_time = inst.run_mrsort()\n",
    "print(\"Time (s) : %f\" % execution_time) # computational time of the running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the parameters of the model learned :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        c1    c2    c3    c4      c5 \n",
      "b1 0.69701 0.832  0.33 0.336 0.59101 \n",
      "      c1     c2    c3     c4     c5 \n",
      "w 0.0001 0.4998     0 0.0002 0.4999 \n",
      "lambda\t0.5001\n"
     ]
    }
   ],
   "source": [
    "inst.model2.bpt.display()\n",
    "inst.model2.cv.display()\n",
    "print(\"lambda\\t%.7s\" % inst.model2.lbda) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also display the learned preference directions : (+) for an increasing direction and (-) for a decreasing preference direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[c1 (+), c2 (+), c3 (+), c4 (+), c5 (+)]\n"
     ]
    }
   ],
   "source": [
    "print(list(inst.model2.criteria))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 : validate the learning of the random model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the CA for the validation of the model regarding the learning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation rate : 1.000000\n"
     ]
    }
   ],
   "source": [
    "ca_v,cag_v = inst.eval_model_validation() # calculating the validation rate\n",
    "print(\"validation rate : %f\" % ca_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also draw the confusion matrix of the validation phase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cat1 cat2 \n",
      "cat1   27    0 \n",
      "cat2    0   23 \n"
     ]
    }
   ],
   "source": [
    "matrix = compute_confusion_matrix(inst.aa, inst.aa_learned, inst.model.categories) # construction of the confusion matrix\n",
    "print_confusion_matrix(matrix, inst.model.categories) # printing the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7 : test the learned algorithm on a benchmarch of alternatives examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogously, we can calculate the CA for the test phase regarding a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rate : 0.940400\n"
     ]
    }
   ],
   "source": [
    "ao_tests,al_tests,ca_t,cag_t = inst.eval_model_test()\n",
    "print(\"test rate : %f\" % ca_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8 : show the important results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to present generalized statistics, we need to carry out the algorithm runnings several times yielding *nb_models* learned models. To do so, we can straightforwardly execute :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.run_mrsort_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATADIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, all the tests are done and we have also generated a csv file summarizing the tests and giving details on each one. This file is found on the directory *rand_valid_test_na100_nca2_ncr5-0_dupl1* visible from the root directory of this notebook. The file name begins with \"valid_test_dupl....\" ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another csv file is the file that contains more compact data facilitating the drawing of different plots. This file is generated with the command line :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.report_plot_results_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It yields a csv file, which name begins by \"plot_results....\" in the same directory as the previous file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final function of this section is the function that ouputs an instance of the learning algorithm (criteria, categories, performance tables and assignments, all codified in a customized syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/pegdwendeminoungou/python_workspace/MRSort-jupyter-notebook/rand_valid_test_na50_nca2_ncr5-0_dupl1//osomcda_rand-50-2-5-1-20200427-221950.csv'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst.build_osomcda_instance_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output file is also in the previous directory as the previous files."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Statistics :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA (validation) :  1.0\n",
      "CA (generalization) :  0.8812200000000001\n",
      "CA (preference direction) :  0.8\n",
      "Time execution (seconds) :  12.200940465927124\n"
     ]
    }
   ],
   "source": [
    "print(\"CA (validation) : \" ,inst.stats_cav)\n",
    "print(\"CA (generalization) : \" ,inst.stats_cag)\n",
    "print(\"CA (preference direction) : \" ,inst.stats_capd)\n",
    "print(\"Time execution (seconds) : \" ,inst.stats_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
